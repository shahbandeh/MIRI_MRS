{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe7b5de-9195-4568-86ed-7f84e142ce85",
   "metadata": {},
   "source": [
    "# JWST MIRI MRS reductions for point sources \n",
    "\n",
    "**Author**: Melissa Shahbandeh\n",
    "<br>\n",
    "**Last Updated**: August, 2023\n",
    "\n",
    "If you use this notebook, please consider citing the GitHub link (https://github.com/shahbandeh/MIRI_MRS) and Shahbandeh et al. 2023b in prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb400013-77dc-4d9d-802c-cf1a9d2606c9",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#intro)<br>\n",
    "2. Setup\\\n",
    "    2.1 Define a path, name of the target, and PID\\\n",
    "    2.2 Python imports\\\n",
    "    2.3 Change the following accordingly to define your CRDS path\\\n",
    "    2.4 Define directories/paths\\\n",
    "    2.5 Organizing data\n",
    "3. Creating the unsubtracted cube\\\n",
    "    3.1 Running stage 1\\\n",
    "    3.2 Removing bad pixels\\\n",
    "    3.3 Running stage 2\\\n",
    "    3.4 Running stage 3\\\n",
    "    3.5 Let's take a look at the cube\n",
    "4. Construct a master background\\\n",
    "    4.1 Defining the extraction functions and finding where the target is\\\n",
    "    4.2 Defining the background regions and extract them\\\n",
    "    4.3  Averaging the background spectra to get the master background and then plot them\\\n",
    "    4.4  Create background subtracted cube\\\n",
    "    4.5 Let's take a look at the subtracted cube\n",
    "5. Residual backgrounds\\\n",
    "    5.1 Changing the source type\\\n",
    "    5.2 Extract residual backgrounds from the subtracted cube\\\n",
    "    5.3 Averaging the background spectra to get the mean residual background and then plot them\n",
    "6. Comparison\\\n",
    "    6.1 Plotting all backgrounds and residuals to compare\\\n",
    "    6.2 Perform an annulus on the subtracted cube to reduce the noise\n",
    "7. Plot all of the residual backgrounds and the target spectrum  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233da518-e10d-4f86-82f8-3f486c1579dc",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d170e4c-c0d1-47b1-a763-5e0a843331cc",
   "metadata": {},
   "source": [
    "**Goals**: \n",
    "\n",
    "Some of the MIRI/MRS targets are either located in the regions with high/complicated backgrounds, or are too faint, or both. This is an attempt to find a better way than what the current pipeline offers to subtract/mitigate the effect of these high background regions. The official pipeline uses an annulus around the target to subtract the background, which is not ideal in the cases with highly varying backgrounds. \n",
    "\n",
    "This notebook shows:\n",
    "\n",
    "1) How to construct a background that is more representative of the background variation\n",
    "2) How to subtract the background and extract the final spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280af14-a191-48d5-a6e3-07d0c6fa3029",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287eff7-cd96-410a-855e-6ffe218d4911",
   "metadata": {},
   "source": [
    "### 2.1<font color='white'>-</font>Define a path, name of the target, and PID<a class=\"anchor\" id=\"Define a path, name of the target, and PID\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d146871-8c7f-44f2-a716-febafbf879c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PID, SN = 1860, '2005ip'\n",
    "path = '/Users/mshahbandeh/JWST/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59e422-af3b-4d7d-b039-039cf6197683",
   "metadata": {},
   "source": [
    "### 2.2<font color='white'>-</font>Python imports<a class=\"anchor\" id=\"Python imports\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fee55-5c1b-495c-8a9c-17f88e57f093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re,sys,os,pdb\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import jwst\n",
    "from jwst.stpipe import Step\n",
    "from jwst.combine_1d import Combine1dStep\n",
    "from specutils import Spectrum1D, SpectrumList\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.visualization import (LinearStretch, LogStretch, ImageNormalize, ZScaleInterval)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import Normalize,LogNorm\n",
    "from matplotlib import rc\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "from jwst import datamodels\n",
    "from jwst.associations import asn_from_list as afl\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from stcal import dqflags\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "usage = 'all'\n",
    "import matplotlib.cm as cmap\n",
    "import sklearn.preprocessing as preprocess\n",
    "from jwst.assign_wcs import AssignWcsStep\n",
    "from jwst.background import BackgroundStep\n",
    "from jwst.flatfield import FlatFieldStep\n",
    "from jwst.srctype import SourceTypeStep\n",
    "from jwst.straylight import StraylightStep\n",
    "from jwst.fringe import FringeStep\n",
    "from jwst.photom import PhotomStep\n",
    "from jwst.cube_build import CubeBuildStep\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "from jwst.cube_skymatch import CubeSkyMatchStep\n",
    "from jwst.master_background import MasterBackgroundStep\n",
    "from jwst.outlier_detection import OutlierDetectionStep\n",
    "import jdaviz\n",
    "from jdaviz import Cubeviz\n",
    "from jwst.datamodels import JwstDataModel, SpecModel, MultiSpecModel, IFUCubeModel, ModelContainer, IFUImageModel\n",
    "import warnings\n",
    "import matplotlib.patches as patches\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import ICRS, Galactic, FK4, FK5\n",
    "from astropy.table import Table\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils import DAOStarFinder, CircularAperture\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(jwst.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45882c5f-366e-4b5d-b48f-9d2f1fb2d859",
   "metadata": {},
   "source": [
    "### 2.3<font color='white'>-</font>Change the following accordingly to define your CRDS path<a class=\"anchor\" id=\"Change the following accordingly to define your CRDS path\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a688533-cc9f-4aa2-a243-dc5f1dbcb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds-pub.stsci.edu\"`\n",
    "# os.environ[\"CRDS_PATH\"] = \"/user/myself/crds_cache\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a909770-39ee-4966-9b23-9c5e49a8b559",
   "metadata": {},
   "source": [
    "### 2.4<font color='white'>-</font>Define directories/paths<a class=\"anchor\" id=\"Define directories/paths\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360847e6-8c81-4d12-9c3a-725748f52b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Point to where you want the output science results to go\n",
    "output_dir = path + f'{PID}/{SN}/'\n",
    "\n",
    "dodet1 = True\n",
    "dospec2 = True\n",
    "dospec3 = True\n",
    "dodet1bg = False\n",
    "dospec2bg = False\n",
    "  \n",
    "## Output subdirectories to keep science data products organized\n",
    "## Note that the pipeline might complain about this as it is intended to work with everything in a single\n",
    "## directory, but it nonetheless works fine for the examples given here.\n",
    "uncal_dir = os.path.join(output_dir, 'stage0/') # Uncalibrated files should be here\n",
    "det1_dir = os.path.join(output_dir, 'stage1/') # Detector1 pipeline outputs will go here\n",
    "spec2_dir = os.path.join(output_dir, 'stage2/') # Spec2 pipeline outputs will go here\n",
    "spec3_dir = os.path.join(output_dir, 'stage3/') # Spec3 pipeline outputs will go here\n",
    "bg_dir = os.path.join(spec3_dir, 'bgs/') # Background files will go here\n",
    "\n",
    "# We need to check that the desired output directories exist, and if not create them\n",
    "if not os.path.exists(uncal_dir):\n",
    "    os.makedirs(uncal_dir)\n",
    "if not os.path.exists(det1_dir):\n",
    "    os.makedirs(det1_dir)\n",
    "if not os.path.exists(spec2_dir):\n",
    "    os.makedirs(spec2_dir)\n",
    "if not os.path.exists(spec3_dir):\n",
    "    os.makedirs(spec3_dir)\n",
    "if not os.path.exists(bg_dir):\n",
    "    os.makedirs(bg_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfffb0-ad97-4b43-84f4-c0f84b7af3d3",
   "metadata": {},
   "source": [
    "### 2.5<font color='white'>-</font>Organizing data<a class=\"anchor\" id=\"Organizing data\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e5bbb-f4b8-437f-ac4a-07fe00a44138",
   "metadata": {},
   "source": [
    "Download the uncalibrated files and put them in \"uncal_dir\" (if you have 4 dithers, you should have 24 files in your uncal_dir)\n",
    "You can skip this stage and instead download the rate files and put them det1_dir in rate files and put them in det1_dir, if you do so then skip to 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5addf-8e0b-4cfc-8de7-e4e8919f47fa",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Creating the unsubtracted cube<a class=\"anchor\" id=\"Creating the unsubtracted cube\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad5876-8a3e-4a21-bc98-65e1d8e44ec0",
   "metadata": {},
   "source": [
    "### 3.1<font color='white'>-</font>Running stage 1<a class=\"anchor\" id=\"Running stage 1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a9ce2-47a0-4db1-adef-b64b44c818ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First we'll define a function that will call the detector1 pipeline with our desired set of parameters\n",
    "# We won't enumerate the individual steps\n",
    "def rundet1(filename, outdir):\n",
    "    print(filename)\n",
    "    det1 = Detector1Pipeline() # Instantiate the pipeline\n",
    "    det1.output_dir = outdir # Specify where the output should go        \n",
    "    det1.save_results = True # Save the final resulting _rate.fits files\n",
    "    det1(filename) # Run the pipeline on an input list of files\n",
    "\n",
    "### Now let's look for input files of the form *uncal.fits from the science observation\n",
    "sstring = uncal_dir + 'jw*mirifu*uncal.fits'\n",
    "lvl1b_files = sorted(glob.glob(sstring))\n",
    "print('Found ' + str(len(lvl1b_files)) + ' science input files to process')\n",
    "\n",
    "if dodet1:\n",
    "    for file in lvl1b_files:\n",
    "        rundet1(file, det1_dir)\n",
    "else:\n",
    "    print('Skipping Detector1 processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab92fce-7c85-4ed8-ade8-17ad0c60c1e4",
   "metadata": {},
   "source": [
    "### 3.2<font color='white'>-</font>Removing bad pixels<a class=\"anchor\" id=\"Removing bad pixels\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca53ba-c416-4c50-85fe-20316bfa5b9c",
   "metadata": {},
   "source": [
    "This is optional in case your data is very noisy and has a lot of bad pixels. DO NOT try it if you expect to have lots of narrow emission lines."
   ]
  },
  {
   "cell_type": "raw",
   "id": "15b86cc9-ce9e-417c-b579-1173632cbbca",
   "metadata": {
    "tags": []
   },
   "source": [
    "listi = ['*02101*fushort*rate.fits','*04101*fushort*rate.fits','*06101*fushort*rate.fits','*02101*fulong*rate.fits','*04101*fulong*rate.fits',\n",
    "       '*06101*fulong*rate.fits']\n",
    "\n",
    "for k in range(len(listi)):\n",
    "    \n",
    "    files = np.array(sorted(glob.glob(det1_dir + listi[k])))\n",
    "\n",
    "    alldata = np.zeros([4,1024,1032])\n",
    "    for ii in range(0,4):\n",
    "        hdu = fits.open(files[ii])\n",
    "        sci = hdu['SCI'].data\n",
    "        alldata[ii,:,:]=sci\n",
    "        hdu.close()\n",
    "\n",
    "    meddata = np.nanmedian(alldata,axis=0)\n",
    "\n",
    "    temp = fits.PrimaryHDU(meddata)\n",
    "    temp.writeto('test.fits',overwrite=True)\n",
    "\n",
    "    # plt.plot(meddata.ravel(),'.')\n",
    "\n",
    "    indx = np.where(meddata > np.nanpercentile(meddata,99.9))\n",
    "    np.nanpercentile(meddata,99.9)\n",
    "\n",
    "    for ii in range(0,4):\n",
    "        hdu = fits.open(files[ii])\n",
    "        sci = hdu['SCI'].data\n",
    "        dq = hdu['DQ'].data\n",
    "        sci[indx] = np.nan\n",
    "        dq[indx] = 1\n",
    "        hdu.writeto(files[ii].replace('rate','ratemod'),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a72754-848b-4415-a291-905a734b0efc",
   "metadata": {},
   "source": [
    "### 3.3<font color='white'>-</font>Running stage 2<a class=\"anchor\" id=\"Running stage 2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92825f3e-6e38-407c-83eb-d0a397a437d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runspec2(filename, outdir, nocubes=False):\n",
    "    spec2 = Spec2Pipeline()\n",
    "    spec2.output_dir = outdir\n",
    "    spec2.assign_wcs.skip = False\n",
    "    spec2.fringe.skip = False\n",
    "    spec2.photom.skip = False\n",
    "    spec2.residual_fringe.skip = False    \n",
    "    spec2.save_results = True\n",
    "    spec2(filename)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Look for uncalibrated science slope files from the Detector1 pipeline\n",
    "sstring = det1_dir + 'jw*mirifu*rate.fits'\n",
    "ratefiles = sorted(glob.glob(sstring))\n",
    "print('Found ' + str(len(ratefiles)) + ' input files to process')\n",
    "#\n",
    "if dospec2:\n",
    "    for file in ratefiles:\n",
    "        runspec2(file, spec2_dir, nocubes=False)\n",
    "else:\n",
    "    print('Skipping Spec2 processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72082abb-5de7-4059-bf19-2fa6ec88a4cb",
   "metadata": {},
   "source": [
    "### 3.4<font color='white'>-</font>Running stage 3<a class=\"anchor\" id=\"Running stage 3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9105c-6320-4d8c-8b79-540c1a56fd06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the association file\n",
    "def writel3asn(scifiles, asnfile, prodname):\n",
    "   # Define the basic association of science files\n",
    "    asn = afl.asn_from_list(scifiles, rule=DMS_Level3_Base, product_name=prodname)\n",
    "   # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)\n",
    "\n",
    "sstring = spec2_dir + 'jw*mirifu*rate*cal.fits'\n",
    "calfiles = np.array(sorted(glob.glob(sstring)))\n",
    "\n",
    "print('Found ' + str(len(calfiles)) + ' science files to process')\n",
    "\n",
    "asnfile = os.path.join(output_dir, 'asn_1.json')\n",
    "if dospec3:\n",
    "    writel3asn(calfiles, asnfile, 'Level3')\n",
    "\n",
    "########################################################################\n",
    "\n",
    "def runspec3(filename, nocubes=True):\n",
    "    crds_config = Spec3Pipeline.get_config_from_reference(filename)\n",
    "    spec3 = Spec3Pipeline.from_config_section(crds_config)\n",
    "    spec3.output_dir = spec3_dir\n",
    "    spec3.save_results = True\n",
    "    spec3.cube_build.output_type = 'multi' # 'band', 'channel', or 'multi' type cube output\n",
    "    spec3.master_background.skip = True # Do not change\n",
    "    spec3.outlier_detection.skip = False\n",
    "    spec3.outlier_detection.kernel_size = '11 1'\n",
    "    spec3.outlier_detection.threshold_percent = 99.8\n",
    "    spec3.mrs_imatch.skip = True\n",
    "    spec3.extract_1d.subtract_background = False # Do not change\n",
    "    spec3.cube_build.output_file = f'{SN}_POINT'\n",
    "    spec3(filename)\n",
    "    \n",
    "if dospec3:\n",
    "    runspec3(asnfile,nocubes=False)\n",
    "else:\n",
    "    print('Skipping Spec3 processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766ff30-772d-4ddf-9d5d-d14efa4040e0",
   "metadata": {},
   "source": [
    "### 3.5<font color='white'>-</font>Let's take a look at the cube<a class=\"anchor\" id=\"Let's take a look at the cube\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ab9aa-5270-4404-81e0-157e1ad1b204",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubeviz = Cubeviz()\n",
    "cubeviz.load_data(spec3_dir+f'{SN}_POINT_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "cubeviz.app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae1fa2-d3dd-40e7-82ec-6f075f7b6a87",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Construct a master background<a class=\"anchor\" id=\"Construct a master background\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e170c-6adb-45dc-8297-1e53d683b11a",
   "metadata": {},
   "source": [
    "### 4.1<font color='white'>-</font>Defining the extraction functions and finding where the target is<a class=\"anchor\" id=\"Defining the extraction functions and finding where the target is\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb0eac-7a23-4392-860e-4788b40de8aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the extraction function\n",
    "def runex(filename, outdir, outputfile):\n",
    "    ex1d = jwst.extract_1d.Extract1dStep()\n",
    "    ex1d.output_dir = outdir\n",
    "    ex1d.save_results = True\n",
    "    ex1d.subtract_background = False # Do not change\n",
    "    ex1d.output_file = outputfile\n",
    "    ex1d(filename)  \n",
    "\n",
    "########################################################################\n",
    "# Defining the averaging function\n",
    "def SBM(spectra_list):\n",
    "    SBs, FLs, BKs = [], [], []\n",
    "    for i in range(len(spectra_list)):\n",
    "        file = fits.open(spectra_list[i])\n",
    "        spec = file['EXTRACT1D'].data[0::]\n",
    "        SBs.append(spec['SURF_BRIGHT'])\n",
    "        FLs.append(spec['FLUX'])\n",
    "        BKs.append(spec['BACKGROUND'])\n",
    "    mean_SB, mean_FL, mean_BK = np.mean(SBs, axis=0), np.mean(FLs, axis=0), np.mean(BKs, axis=0)\n",
    "    # median_SB, median_FL, median_BK = np.median(SBs, axis=0), np.median(FLs, axis=0), np.median(BKs, axis=0)\n",
    "    # return median_FL, median_SB, median_BK\n",
    "    return mean_FL, mean_SB, mean_BK\n",
    "########################################################################\n",
    "# Changing source type\n",
    "spec_model_cube = IFUCubeModel()\n",
    "spec_model_cube.read(spec3_dir+f'{SN}_POINT_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "spec_model_cube.meta.target.source_type = 'EXTENDED'\n",
    "spec_model_cube.save(spec3_dir+f'{SN}_EXTENDED_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "\n",
    "x_dim = spec_model_cube.data.shape[0]\n",
    "y_dim = spec_model_cube.data.shape[1]\n",
    "z_dim = spec_model_cube.data.shape[2]\n",
    "\n",
    "ra0,dec0 = spec_model_cube.meta.target.ra, spec_model_cube.meta.target.dec\n",
    "med_cube = np.zeros((y_dim, z_dim))\n",
    "\n",
    "# Finding the brightest point source in the collapsed cube (sometimes the target is not exactly located at the RA and DEC defined in the header)\n",
    "for a in range(y_dim):\n",
    "    for b in range(z_dim):\n",
    "        med_cube[a,b] = np.median(spec_model_cube.data[:,a,b])\n",
    "mean, median, std = sigma_clipped_stats(med_cube, sigma = 2.0)\n",
    "daofind = DAOStarFinder(fwhm = 2.0, threshold = 5. * std)\n",
    "sources = daofind(med_cube - median)\n",
    "positions = Table([sources['xcentroid'], sources['ycentroid']])\n",
    "peakpixval = np.zeros(len(sources['xcentroid']))\n",
    "for count_s, _ in enumerate(sources):\n",
    "    peakpixval[count_s] = med_cube[int(np.round(sources['xcentroid'][count_s])), int(np.round(sources['ycentroid'][count_s]))]\n",
    "targ_y, targ_z = sources['xcentroid'][np.argmax(peakpixval)], sources['ycentroid'][np.argmax(peakpixval)]\n",
    "\n",
    "#checking that targ_y, and targ_z should be around 35,50, respectively. If it is not then change the threshold above.\n",
    "print(targ_y,targ_z)\n",
    "\n",
    "xcen, ycen = targ_y, targ_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c73f7a-8bef-4182-95f2-a07896beee7e",
   "metadata": {},
   "source": [
    "### 4.2<font color='white'>-</font>Defining the background regions and extract them<a class=\"anchor\" id=\"Defining the background regions and extract them\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4dd9a-accc-4d49-a139-ebcc87603897",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining where the regions start, y is the horizontal, and z is the vertical axes\n",
    "filters = {\n",
    "    'bg1': {'y': (40,45), 'z': (65,70)},\n",
    "    'bg2': {'y': (46,52), 'z': (70,73)},\n",
    "    'bg3': {'y': (20,26), 'z': (57,60)},\n",
    "    'bg4': {'y': (50,55), 'z': (35,40)},\n",
    "    'bg5': {'y': (26,31), 'z': (30,39)},\n",
    "    'bg6': {'y': (35,40), 'z': (55,60)},\n",
    "    'bg7': {'y': (20,30), 'z': (15,20)},\n",
    "    'bg8': {'y': (40,50), 'z': (30,40)},\n",
    "    'bg9': {'y': (25,30), 'z': (25,30)},\n",
    "    'bg10': {'y': (18,30), 'z': (22,38)},\n",
    "    'bg11': {'y': (40,60), 'z': (20,40)},\n",
    "    'bg12': {'y': (60,70), 'z': (40,60)},\n",
    "    'bg13': {'y': (10,70), 'z': (30,60)},\n",
    "}\n",
    "\n",
    "Ch_edges = [0,3279,6226,8608]\n",
    "\n",
    "# Width of the background regions, so wd=10 is 10by10 square; adjust accordingly if your cube is much bigger or smaller.\n",
    "wd, slc = 10, 800\n",
    "\n",
    "for key,region in filters.items():\n",
    "    # Python reads x,y pixels as y,x, so we switch them\n",
    "    z_range = region['y']\n",
    "    y_range = region['z']\n",
    "    spec_model_cube = IFUCubeModel()\n",
    "    spec_model_cube.read(spec3_dir+f'{SN}_EXTENDED_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "    nan_mask = np.ones((x_dim,y_dim,z_dim))*np.nan\n",
    "    zero_mask = np.zeros((x_dim,y_dim,z_dim))\n",
    "\n",
    "    # Checking to see if the background regions look ok and do not cover the target (if so change the wd)\n",
    "    fig1, axes = plt.subplots(nrows=1,ncols=4,figsize=(16,4))\n",
    "    for i in range(len(Ch_edges)):\n",
    "        nan_mask[Ch_edges[i] + slc, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd] = spec_model_cube.data[Ch_edges[i] + slc, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]\n",
    "        axes[i].imshow(spec_model_cube.data[Ch_edges[i] + slc, :, :], origin='lower', cmap='gray',alpha=0.5)\n",
    "        axes[i].imshow(nan_mask[Ch_edges[i] + slc, :, :], origin='lower', cmap='Blues',alpha=1)\n",
    "        axes[i].text(65, 85, 'CH'+str(i+1)+'--'+key, fontsize=10, ha='center', va='center')\n",
    "        \n",
    "    # Mask everything but the backgrounds\n",
    "    for x in range(x_dim):\n",
    "        zero_mask[x, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd] = spec_model_cube.weightmap[x, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]\n",
    "        \n",
    "    spec_model_cube.weightmap = zero_mask\n",
    "\n",
    "    runex(spec_model_cube, bg_dir, outputfile=f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_BS.fits')\n",
    "    \n",
    "    try:\n",
    "        fig2, axes = plt.subplots()\n",
    "        spec = fits.open(bg_dir+f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_BS_extract1dstep.fits')\n",
    "        wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "        plt.plot(wave, flux)\n",
    "        plt.show()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad46c5-e18a-4e51-abee-07f3d425fd67",
   "metadata": {},
   "source": [
    "### 4.3<font color='white'>-</font>Averaging the background spectra to get the master background and then plot them<a class=\"anchor\" id=\" Averaging the background spectra to get the master background and then plot them\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df10093-0523-4c8b-b960-f2b32c9d2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging them\n",
    "sstring = bg_dir + 'bg*y*_BS_extract1dstep.fits'\n",
    "bgfiles = sorted(glob.glob(sstring))\n",
    "mean_FL, mean_SB, mean_BK = SBM(bgfiles)\n",
    "\n",
    "# Creating the mean/master background\n",
    "hdu = fits.open(bgfiles[0])\n",
    "fl = np.zeros(len(hdu[1].data))\n",
    "otab = np.array(list(zip(hdu[1].data['wavelength'], *([fl] * 17))), dtype=datamodels.SpecModel().spec_table.dtype)\n",
    "model = datamodels.SpecModel(spec_table=otab)\n",
    "model.spec_table['FLUX'], model.spec_table['SURF_BRIGHT'] = mean_FL, mean_SB\n",
    "multimod = datamodels.MultiSpecModel()\n",
    "multimod.spec.append(model)\n",
    "multimod.save(bg_dir + f'mean_bg_{wd}X{wd}pix_BS.fits')\n",
    "\n",
    "# Plotting all bgs again plus the mean bg\n",
    "for i in range(len(bgfiles)):\n",
    "    spec = fits.open(bgfiles[i])\n",
    "    wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "    plt.plot(wave, flux)\n",
    "    \n",
    "spec = fits.open(bg_dir + f'mean_bg_{wd}X{wd}pix_BS.fits')\n",
    "wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "plt.plot(wave,flux, label='mean background',color='red')\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel('F [Jy]')\n",
    "plt.legend()\n",
    "plt.savefig(bg_dir + 'all_bg_and_mean_BS.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605027c8-4d4a-4824-80f0-6843800fe91a",
   "metadata": {},
   "source": [
    "### 4.4<font color='white'>-</font> Create background subtracted cube<a class=\"anchor\" id=\"Create background subtracted cube\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563c51e-ff0c-42e9-9d99-fdaafbee98e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def writel3asn(scifiles, bgfiles, asnfile, prodname):\n",
    "   # Define the basic association of science files\n",
    "    asn = afl.asn_from_list(scifiles, rule=DMS_Level3_Base, product_name=prodname)\n",
    "\n",
    "   # Add background files to the association\n",
    "    nbg = len(bgfiles)\n",
    "    for ii in range(0,nbg):\n",
    "        asn['products'][0]['members'].append({'expname': bgfiles[ii], 'exptype': 'background'})\n",
    "\n",
    "   # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)\n",
    "\n",
    "sstring = spec2_dir + 'jw*mirifu*rate*cal.fits'\n",
    "calfiles = np.array(sorted(glob.glob(sstring)))\n",
    "\n",
    "sstring = bg_dir + f'mean_bg_{wd}X{wd}pix_BS.fits'\n",
    "bgfiles = np.array(sorted(glob.glob(sstring)))\n",
    "\n",
    "print('Found ' + str(len(calfiles)) + ' science files to process')\n",
    "print('Found ' + str(len(bgfiles)) + ' background files to process')\n",
    "\n",
    "asnfile = os.path.join(output_dir, 'asn_file_subtracted.json')\n",
    "if dospec3:\n",
    "    writel3asn(calfiles, bgfiles, asnfile, 'Level3')\n",
    "    \n",
    "########################################################################\n",
    "\n",
    "def runspec3(filename, nocubes=True):\n",
    "    crds_config = Spec3Pipeline.get_config_from_reference(filename)\n",
    "    spec3 = Spec3Pipeline.from_config_section(crds_config)\n",
    "    spec3.output_dir = spec3_dir\n",
    "    spec3.save_results = True\n",
    "    spec3.cube_build.output_type = 'multi' # 'band', 'channel', or 'multi' type cube output\n",
    "    spec3.master_background.skip = False\n",
    "    spec3.master_background.save_background = False\n",
    "    spec3.master_background.save_results = False\n",
    "    spec3.master_background.user_background = bg_dir + f'mean_bg_{wd}X{wd}pix_BS.fits' # The mean background we built earlier\n",
    "    spec3.master_background.force_subtract = True\n",
    "    spec3.outlier_detection.skip = False\n",
    "    spec3.outlier_detection.kernel_size = '11 1'\n",
    "    spec3.outlier_detection.threshold_percent = 99.8\n",
    "    spec3.mrs_imatch.skip = True\n",
    "    spec3.extract_1d.subtract_background = False\n",
    "    spec3.extract_1d.use_source_posn = True\n",
    "    spec3.extract_1d.center_xy = (xcen,ycen) # Override aperture location if desired using the brightest source we found earlier\n",
    "    spec3.extract_1d.ifu_rfcorr = True # Turn on 1d residual fringe correction\n",
    "    spec3.cube_build.output_file = f'{SN}_subtracted_{wd}X{wd}pix'\n",
    "    spec3(filename)\n",
    "    \n",
    "if dospec3:\n",
    "    runspec3(asnfile,nocubes=False)\n",
    "else:\n",
    "    print('Skipping Spec3 processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c39b3-50bf-4c88-9f49-8c5ced7aa053",
   "metadata": {},
   "source": [
    "### 4.5<font color='white'>-</font>Let's take a look at the subtracted cube<a class=\"anchor\" id=\"Let's take a look at the subtracted cube\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbfb61-282c-45e3-99d8-cea5c241f059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubeviz = Cubeviz()\n",
    "cubeviz.load_data(spec3_dir+f'{SN}_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "cubeviz.app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec3f5c-8986-4c17-8c11-50df7bc7f93d",
   "metadata": {},
   "source": [
    "5.<font color='white'>-</font>Residual backgrounds<a class=\"anchor\" id=\"Residual backgrounds\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734f0b8-f88d-4d88-b5d2-8a8dcfae09dc",
   "metadata": {},
   "source": [
    "### 5.1<font color='white'>-</font>Changing the source type<a class=\"anchor\" id=\"Changing the source type\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb811a9-0a67-46dc-b23a-3b86a894dd07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changing source type\n",
    "spec_model_cube = IFUCubeModel()\n",
    "spec_model_cube.read(spec3_dir+f'{SN}_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "spec_model_cube.meta.target.source_type = 'EXTENDED'\n",
    "spec_model_cube.save(spec3_dir+f'{SN}_EXTENDED_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec9535-46d1-42fc-8147-cefbbe7cd5c0",
   "metadata": {},
   "source": [
    "### 5.2<font color='white'>-</font>Extract residual backgrounds from the subtracted cube<a class=\"anchor\" id=\"Extract residual backgrounds from the subtracted cube\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c04a7-7db8-4781-8282-635f325f3cf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as before but this time on subtracted cube\n",
    "for key,region in filters.items():\n",
    "    z_range = region['y']\n",
    "    y_range = region['z']\n",
    "    spec_model_cube = IFUCubeModel()\n",
    "    spec_model_cube.read(spec3_dir+f'{SN}_EXTENDED_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "    nan_mask = np.ones((x_dim,y_dim,z_dim))*np.nan\n",
    "    zero_mask = np.zeros((x_dim,y_dim,z_dim))\n",
    "    \n",
    "    #checking background regions\n",
    "    fig1, axes = plt.subplots(nrows=1,ncols=4,figsize=(16,4))\n",
    "    for i in range(len(Ch_edges)):\n",
    "        nan_mask[Ch_edges[i]+slc, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]=spec_model_cube.data[Ch_edges[i]+slc, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]\n",
    "        axes[i].imshow(spec_model_cube.data[Ch_edges[i]+slc, :, :], origin='lower', cmap='gray',alpha=0.5)\n",
    "        axes[i].imshow(nan_mask[Ch_edges[i]+slc, :, :], origin='lower', cmap='Blues',alpha=1)\n",
    "        axes[i].text(65, 85, 'CH'+str(i+1)+'--'+key, fontsize=10, ha='center', va='center')\n",
    "\n",
    "    for x in range(x_dim):\n",
    "        zero_mask[x, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]=spec_model_cube.weightmap[x, y_range[0]:y_range[0]+wd, z_range[0]:z_range[0]+wd]\n",
    "        \n",
    "    spec_model_cube.weightmap=zero_mask\n",
    "\n",
    "    runex(spec_model_cube, bg_dir, outputfile=f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_AS.fits')\n",
    "    \n",
    "    try:\n",
    "        fig2, axes = plt.subplots()\n",
    "        spec=fits.open(bg_dir+f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_AS_extract1dstep.fits')\n",
    "        wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "        plt.plot(wave, flux)\n",
    "        plt.show()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ecc6e1-ecfa-4f40-881e-039eedb67d88",
   "metadata": {},
   "source": [
    "### 5.3<font color='white'>-</font>Averaging the residual background spectra to get the mean residual background and then plot them<a class=\"anchor\" id=\"Averaging the background spectra to get the mean residual background and then plot them\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c7278-07b8-4468-827f-c1009ca57f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstring = bg_dir + 'bg*y*_AS_extract1dstep.fits'\n",
    "bgfiles = sorted(glob.glob(sstring))\n",
    "mean_FL, mean_SB, mean_BK = SBM(bgfiles)\n",
    "\n",
    "hdu = fits.open(bgfiles[0])\n",
    "fl = np.zeros(len(hdu[1].data))\n",
    "otab = np.array(list(zip(hdu[1].data['wavelength'], *([fl] * 17))), dtype=datamodels.SpecModel().spec_table.dtype)\n",
    "model = datamodels.SpecModel(spec_table=otab)\n",
    "model.spec_table['FLUX'], model.spec_table['SURF_BRIGHT'] = mean_FL, mean_SB\n",
    "multimod = datamodels.MultiSpecModel()\n",
    "multimod.spec.append(model)\n",
    "multimod.save(bg_dir + f'mean_bg_{wd}X{wd}pix_AS.fits')\n",
    "\n",
    "#plotting all bgs again plus the mean bg\n",
    "for i in range(len(bgfiles)):\n",
    "    spec=fits.open(bgfiles[i])\n",
    "    wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "    plt.plot(wave, flux)\n",
    "    \n",
    "spec=fits.open(bg_dir + f'mean_bg_{wd}X{wd}pix_AS.fits')\n",
    "wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "plt.plot(wave,flux, label='mean background',color='red')\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel('F [Jy]')\n",
    "plt.legend()\n",
    "plt.savefig(bg_dir + 'all_bg_and_mean_AS.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778c75e-4f2a-4923-ad27-9227081b8d12",
   "metadata": {},
   "source": [
    "6.<font color='white'>-</font>Comparison<a class=\"anchor\" id=\"Comparison\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2a3f5-30f3-4a09-81cd-b3ea016b668f",
   "metadata": {},
   "source": [
    "### 6.1<font color='white'>-</font>Plotting all backgrounds and residuals to compare<a class=\"anchor\" id=\"Plotting all backgrounds and residuals to compare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f82d5-1c42-4911-bfe8-f94f4ab52edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changing source type\n",
    "spec_model_cube = IFUCubeModel()\n",
    "spec_model_cube.read(spec3_dir+f'{SN}_EXTENDED_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "\n",
    "sub_model_cube = IFUCubeModel()\n",
    "sub_model_cube.read(spec3_dir+f'{SN}_EXTENDED_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "\n",
    "nrows = 3*len(filters)\n",
    "figure_height = nrows * 3  # 3 inches per row\n",
    "row_heights = []\n",
    "\n",
    "for i in range(len(filters)):\n",
    "    row_heights.append([1,1,0.5])\n",
    "    \n",
    "row_heights = np.array(row_heights).flatten()\n",
    "\n",
    "fig = plt.figure(figsize=(14, figure_height))\n",
    "gs = gridspec.GridSpec(nrows, 4, figure=fig, height_ratios=row_heights, wspace=0.4, hspace=-0.1)\n",
    "\n",
    "lgnorm = [Normalize(vmin=-100,vmax=100),Normalize(vmin=-100,vmax=150),Normalize(vmin=-50,vmax=200),Normalize(vmin=-100,vmax=400)]\n",
    "\n",
    "###########\n",
    "for j, (key, region) in enumerate(filters.items()):\n",
    "    z_range = region['y']\n",
    "    y_range = region['z']\n",
    "    nan_mask = np.ones((x_dim,y_dim,z_dim))*np.nan\n",
    "\n",
    "    for i in range(len(Ch_edges)):\n",
    "        nan_mask[Ch_edges[i] + slc, y_range[0]:y_range[0] + wd, z_range[0]:z_range[0] + wd] = spec_model_cube.data[Ch_edges[i] + slc, y_range[0]:y_range[0] + wd, z_range[0]:z_range[0] + wd]\n",
    "        ax = fig.add_subplot(gs[j*3, i])\n",
    "        colorbar = plt.colorbar(ax.imshow(spec_model_cube.data[Ch_edges[i] + slc, :, :], origin='lower', cmap='gray',norm=lgnorm[i]),ax=ax,shrink=0.7)\n",
    "        ax.text(15, 88, 'CH' + str(i + 1), fontsize=10, ha='center', va='center',color='black')\n",
    "        ax.imshow(nan_mask[Ch_edges[i] + slc, :, :], origin='lower', cmap='Blues', alpha=1)\n",
    "        if i==0: \n",
    "            ax.text(-15, 90, key, fontsize=15, ha='center', va='center',color='black')\n",
    "            ax.set_ylabel('Original', fontsize=10)\n",
    "        if i==3:\n",
    "            colorbar.set_label('Flux density [MJy/sr]')\n",
    "        \n",
    "    nan_mask = np.ones((x_dim,y_dim,z_dim))*np.nan\n",
    "    for k in range(len(Ch_edges)):\n",
    "        nan_mask[Ch_edges[k] + slc, y_range[0]:y_range[0] + wd, z_range[0]:z_range[0] + wd] = sub_model_cube.data[Ch_edges[k] + slc, y_range[0]:y_range[0] + wd, z_range[0]:z_range[0] + wd]\n",
    "        ax = fig.add_subplot(gs[j*3+1, k])\n",
    "        colorbar = plt.colorbar(ax.imshow(sub_model_cube.data[Ch_edges[k] + slc, :, :], origin='lower', cmap='gray',norm=lgnorm[k]),ax=ax,shrink=0.7)\n",
    "        ax.text(15, 88, 'CH' + str(k + 1), fontsize=10, ha='center', va='center',color='black')\n",
    "        ax.imshow(nan_mask[Ch_edges[k] + slc, :, :], origin='lower', cmap='Oranges')\n",
    "        if k==0: \n",
    "            ax.set_ylabel('Mean bg subtracted', fontsize=10)\n",
    "        if k==3:\n",
    "            colorbar.set_label('Flux density [MJy/sr]')\n",
    "\n",
    "    ax = fig.add_subplot(gs[j*3+2, :])\n",
    "    spec = fits.open(bg_dir + f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_BS_extract1dstep.fits')\n",
    "    wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "    ax.plot(wave, flux, color='dodgerblue',label='Original')\n",
    "    \n",
    "    spec = fits.open(bg_dir + f'{key}_y({y_range[0]},{y_range[0]+wd})_z({z_range[0]}-{z_range[0]+wd})_AS_extract1dstep.fits')\n",
    "    wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "    ax.plot(wave, flux, color='orange',label='After subtraction')\n",
    "    ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# fig.align_labels()\n",
    "plt.savefig(bg_dir + f'{SN}_comparison_bgs_{wd}X{wd}pix.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f17e4-9a51-4839-b7b0-225492bd66ff",
   "metadata": {},
   "source": [
    "### 6.2<font color='white'>-</font>Perform an annulus on the subtracted cube to reduce the noise<a class=\"anchor\" id=\"Perform an annulus on the subtracted cube to reduce the noise\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7368126-b3d7-45f6-8b2b-e79441ff0b96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runex(filename, outdir, outputfile):\n",
    "    ex1d = jwst.extract_1d.Extract1dStep()\n",
    "    ex1d.output_dir = outdir\n",
    "    ex1d.save_results = True\n",
    "    ex1d.use_source_posn = True\n",
    "    ex1d.center_xy = (xcen,ycen)\n",
    "    ex1d.subtract_background = True # Do not change\n",
    "    ex1d.output_file = outputfile\n",
    "    ex1d(filename)  \n",
    "    \n",
    "sub_model_cube = IFUCubeModel()\n",
    "sub_model_cube.read(spec3_dir+f'{SN}_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_s3d.fits')\n",
    "    \n",
    "runex(sub_model_cube, bg_dir, outputfile='Master_and_annulus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ef556-8d93-4faa-b1b7-cafc0d236538",
   "metadata": {},
   "source": [
    "7.<font color='white'>-</font>Plot all of the residual backgrounds and the target spectrum<a class=\"anchor\" id=\"Plot all of the residual backgrounds and the target spectrum\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01619ef3-768f-4fd1-93f8-991e7a82f0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "sstring = bg_dir + '*AS_extract1dstep.fits'\n",
    "bgfiles = sorted(glob.glob(sstring))\n",
    "    \n",
    "flux_list = []\n",
    "\n",
    "for i in range(len(bgfiles)):\n",
    "    spec=fits.open(bgfiles[i])\n",
    "    wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "    flux_list.append(flux)\n",
    "    match = re.search(r\"bg(\\d+)\", str(bgfiles[i]))\n",
    "    bg_num = int(match.group(1))\n",
    "    plt.plot(wave, gaussian_filter1d(flux,5),alpha=0.3, label=f'bg{bg_num}',zorder=-1)\n",
    "\n",
    "# Finding the variation of the backgrounds and plot it as a shaded gray region around the target\n",
    "flux_arr = np.array(flux_list)\n",
    "stdev = np.std(flux_arr, axis=0)\n",
    "    \n",
    "spec=fits.open(bg_dir + f'mean_bg_{wd}X{wd}pix_AS.fits')\n",
    "wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "plt.plot(wave,gaussian_filter1d(flux,3), label='Mean bg',color='red',alpha=0.6)\n",
    "\n",
    "spec=fits.open(spec3_dir+f'{SN}_subtracted_{wd}X{wd}pix_ch1-2-3-4-shortmediumlong_x1d.fits')\n",
    "wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "plt.plot(wave,gaussian_filter1d(flux,5), label='SN (master) +/- stdev',color='black')\n",
    "plt.fill_between(wave, gaussian_filter1d(flux,5) - stdev, gaussian_filter1d(flux,5) + stdev, color='gray', alpha=0.6)\n",
    "\n",
    "spec=fits.open(bg_dir+'Master_and_annulus_extract1dstep.fits')\n",
    "wave, flux = spec[1].data['WAVELENGTH'], spec[1].data['FLUX']\n",
    "plt.plot(wave,gaussian_filter1d(flux,5), label='SN (master+annulus)',color='blue',alpha=0.8)\n",
    "\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel('F [Jy]')\n",
    "plt.ylim(-0.0004,0.0015)\n",
    "plt.xlim(4.8,28)\n",
    "plt.legend(ncols=6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(bg_dir + f'{SN}_vs_bgs.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
